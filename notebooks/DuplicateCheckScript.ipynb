{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7eec9c12-5e20-4fb9-9ac3-082222c6e992",
   "metadata": {},
   "source": [
    "## Duplicate Checking Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06314d14-70b6-4f03-a651-147fa95129d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Options for pandas\n",
    "pd.options.display.max_columns = 50\n",
    "pd.options.display.max_rows = 30\n",
    "\n",
    "# Visualizations\n",
    "import plotly\n",
    "import plotly.graph_objs as go\n",
    "import plotly.offline as ply\n",
    "plotly.offline.init_notebook_mode(connected=True)\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import cufflinks as cf\n",
    "cf.go_offline(connected=True)\n",
    "cf.set_config_file(theme='white')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Autoreload extension\n",
    "if 'autoreload' not in get_ipython().extension_manager.loaded:\n",
    "    %load_ext autoreload\n",
    "    \n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6707af2-204e-44c4-9fc9-098142bb8dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate_data = data.copy()\n",
    "\n",
    "#right, had to create a function to change the datetime data\n",
    "def float_time_to_string(float_time):\n",
    "    hours = int(float_time)\n",
    "    decimal_part = float_time - hours\n",
    "\n",
    "    minutes = int(decimal_part * 60)\n",
    "\n",
    "    return f\"{hours:02d}:{minutes:02d}\"\n",
    "\n",
    "duplicate_data['hora_creacion'] = duplicate_data['hora_creacion'].apply(float_time_to_string)\n",
    "\n",
    "\n",
    "# 'fecha_creacion' and 'hora_creacion' to new column 'datetime' and sort by this column\n",
    "duplicate_data['datetime'] = pd.to_datetime(duplicate_data['fecha_creacion'] + ' ' + duplicate_data['hora_creacion'])\n",
    "duplicate_data = duplicate_data.sort_values(by='datetime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2d73aa-c123-4761-ab78-219b5bcdb6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if it's geographically close\n",
    "def is_close_enough(lat1, lon1, lat2, lon2):\n",
    "    threshold = 0.001  # something close to about 100 meters for latitude\n",
    "    distance_lat = abs(lat1 - lat2)\n",
    "    distance_lon = abs(lon1 - lon2) * math.cos(math.radians((lat1 + lat2) / 2))\n",
    "    return distance_lat < threshold and distance_lon < threshold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3111dddb-ab6d-425b-9e74-a320ccdf5b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# duplicate function, goes through \n",
    "def is_duplicate(row, previous_rows):\n",
    "    for prev_row in previous_rows.itertuples():\n",
    "        # check fifteen minutes\n",
    "        if row.datetime - prev_row.datetime > timedelta(minutes=10):\n",
    "            continue\n",
    "\n",
    "        # check alcaldia\n",
    "        if row.alcaldia_cierre != prev_row.alcaldia_cierre:\n",
    "            continue\n",
    "\n",
    "        # check tipo incident\n",
    "        if row.tipo_incidente_c4 != prev_row.tipo_incidente_c4:\n",
    "            continue\n",
    "\n",
    "        # use proximity function to check how close\n",
    "        if not is_close_enough(row.latitud, row.longitud, prev_row.latitud, prev_row.longitud):\n",
    "            continue\n",
    "\n",
    "        return True  # it's a duplicate (by the standard of our function, we can add more)\n",
    "    return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2c5995-f209-4d4d-a50e-cdcb6dbcd4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add new column to show duplicate\n",
    "duplicate_data['is_duplicate'] = False\n",
    "for index, row in duplicate_data.iterrows():\n",
    "    # limit rows to the last 100\n",
    "    previous_rows = duplicate_data[duplicate_data['datetime'] < row.datetime].tail(100)\n",
    "    duplicate_data.at[index, 'is_duplicate'] = is_duplicate(row, previous_rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d0e2e6-067c-4fe4-ba52-38b23052facd",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate_data.tail(50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61578de7-b872-4a7e-adf5-7d58f44c6992",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate_data.to_csv('data911_dupeCheck.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
